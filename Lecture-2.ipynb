{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lesson_1_(diabetes).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTRagYcvHjDj"
      },
      "source": [
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers import Input, Dropout\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApzFGDkOHnt7"
      },
      "source": [
        "# dataset = pd.read_csv(\"/content/diabetes.csv\") # Reads .csv file as DataFrame.\n",
        "dataset = pd.read_csv(\"/content/diabetes.csv\", header=None).values # Reads .csv file as Numpy Ndarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHfdZheJ_lh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61eafdd-e3b4-4f92-94bf-462c2a561be8"
      },
      "source": [
        "print(type(dataset))\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(768, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt64olkkHwft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe5f64d-208a-4f4a-d4cf-43b6524b2ccb"
      },
      "source": [
        "# Last column is our target [0, 1]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8], test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"X_train.shape: \", X_train.shape)\n",
        "print(\"Y_train.shape: \", Y_train.shape)\n",
        "print(\"X_test.shape: \", X_test.shape)\n",
        "print(\"Y_test.shape: \", Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:  (576, 8)\n",
            "Y_train.shape:  (576,)\n",
            "X_test.shape:  (192, 8)\n",
            "Y_test.shape:  (192,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMfomxTmH3ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b241ca2-88c8-4728-cdb0-5c68abbc1ebc"
      },
      "source": [
        "\n",
        "my_first_nn = Sequential() # create a Sequential model\n",
        "\n",
        "# FIX ME\n",
        "my_first_nn.add(Input(shape=(1,))) # Input Layer\n",
        "\n",
        "my_first_nn.add(Dense(32, activation='relu')) # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
        "\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "print(my_first_nn.summary())\n",
        "\n",
        "# The returned history object holds a record of the loss values and metric values during training\n",
        "history =  my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100, verbose=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,465\n",
            "Trainable params: 2,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 5.1125 - acc: 0.5365 - val_loss: 1.7146 - val_acc: 0.4062\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1699 - acc: 0.5972 - val_loss: 1.1093 - val_acc: 0.5365\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9413 - acc: 0.5799 - val_loss: 0.9468 - val_acc: 0.5469\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7522 - acc: 0.6250 - val_loss: 0.6706 - val_acc: 0.6302\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6203 - acc: 0.6927 - val_loss: 0.6419 - val_acc: 0.6615\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6061 - acc: 0.6771 - val_loss: 0.6633 - val_acc: 0.6667\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6080 - acc: 0.6823 - val_loss: 0.6629 - val_acc: 0.6823\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6055 - acc: 0.6997 - val_loss: 0.7249 - val_acc: 0.6771\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6107 - acc: 0.6615 - val_loss: 0.6750 - val_acc: 0.6719\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5913 - acc: 0.6979 - val_loss: 0.6284 - val_acc: 0.6979\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5979 - acc: 0.6962 - val_loss: 0.6601 - val_acc: 0.6667\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5799 - acc: 0.7135 - val_loss: 0.6620 - val_acc: 0.7083\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6186 - acc: 0.6875 - val_loss: 0.6611 - val_acc: 0.6771\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5691 - acc: 0.7326 - val_loss: 0.6205 - val_acc: 0.6875\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5855 - acc: 0.7083 - val_loss: 0.6532 - val_acc: 0.6927\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6120 - acc: 0.6997 - val_loss: 0.6601 - val_acc: 0.6615\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5719 - acc: 0.7309 - val_loss: 0.6521 - val_acc: 0.7292\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - acc: 0.7135 - val_loss: 0.7187 - val_acc: 0.6771\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5608 - acc: 0.6910 - val_loss: 0.6311 - val_acc: 0.7188\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - acc: 0.7361 - val_loss: 0.6917 - val_acc: 0.6771\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - acc: 0.6892 - val_loss: 0.6533 - val_acc: 0.7188\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5643 - acc: 0.6979 - val_loss: 0.6509 - val_acc: 0.7135\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5480 - acc: 0.7170 - val_loss: 0.6272 - val_acc: 0.6823\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6232 - acc: 0.6736 - val_loss: 0.6326 - val_acc: 0.7031\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5852 - acc: 0.7153 - val_loss: 0.6193 - val_acc: 0.6979\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - acc: 0.7257 - val_loss: 0.6241 - val_acc: 0.7083\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - acc: 0.7309 - val_loss: 0.6247 - val_acc: 0.6875\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5607 - acc: 0.6944 - val_loss: 0.6550 - val_acc: 0.6510\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5858 - acc: 0.7188 - val_loss: 0.7058 - val_acc: 0.6719\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5314 - acc: 0.7500 - val_loss: 0.6743 - val_acc: 0.6927\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5665 - acc: 0.7205 - val_loss: 0.7429 - val_acc: 0.6771\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6069 - acc: 0.7014 - val_loss: 0.6742 - val_acc: 0.6875\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5403 - acc: 0.7292 - val_loss: 0.7779 - val_acc: 0.6510\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - acc: 0.7188 - val_loss: 0.6564 - val_acc: 0.6667\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5412 - acc: 0.7205 - val_loss: 0.7012 - val_acc: 0.7188\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5221 - acc: 0.7448 - val_loss: 0.6316 - val_acc: 0.7083\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - acc: 0.7118 - val_loss: 0.6484 - val_acc: 0.6875\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5160 - acc: 0.7552 - val_loss: 0.6275 - val_acc: 0.7083\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5434 - acc: 0.7292 - val_loss: 0.6757 - val_acc: 0.6875\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - acc: 0.7465 - val_loss: 0.6207 - val_acc: 0.6927\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - acc: 0.7587 - val_loss: 0.6738 - val_acc: 0.6875\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5412 - acc: 0.7431 - val_loss: 0.6379 - val_acc: 0.6927\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5522 - acc: 0.7153 - val_loss: 0.7651 - val_acc: 0.6823\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5564 - acc: 0.7188 - val_loss: 0.6639 - val_acc: 0.6562\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5295 - acc: 0.7378 - val_loss: 0.6384 - val_acc: 0.6979\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5715 - acc: 0.7014 - val_loss: 0.6716 - val_acc: 0.6719\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - acc: 0.7517 - val_loss: 0.6263 - val_acc: 0.7135\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5066 - acc: 0.7431 - val_loss: 0.6269 - val_acc: 0.6875\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - acc: 0.7378 - val_loss: 0.6468 - val_acc: 0.6823\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - acc: 0.7639 - val_loss: 0.7478 - val_acc: 0.6667\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - acc: 0.7413 - val_loss: 0.6692 - val_acc: 0.7135\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5095 - acc: 0.7517 - val_loss: 0.6536 - val_acc: 0.6615\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - acc: 0.7639 - val_loss: 0.6419 - val_acc: 0.7135\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - acc: 0.7604 - val_loss: 0.6571 - val_acc: 0.7188\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5034 - acc: 0.7448 - val_loss: 0.6730 - val_acc: 0.7031\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - acc: 0.7535 - val_loss: 0.6605 - val_acc: 0.7188\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5397 - acc: 0.7257 - val_loss: 0.6620 - val_acc: 0.7240\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5176 - acc: 0.7569 - val_loss: 0.6545 - val_acc: 0.6823\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - acc: 0.7517 - val_loss: 0.6383 - val_acc: 0.7083\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - acc: 0.7552 - val_loss: 0.6687 - val_acc: 0.6927\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4932 - acc: 0.7760 - val_loss: 0.6765 - val_acc: 0.6823\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - acc: 0.7639 - val_loss: 0.6312 - val_acc: 0.6875\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - acc: 0.7726 - val_loss: 0.6393 - val_acc: 0.7083\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - acc: 0.7535 - val_loss: 0.6747 - val_acc: 0.7188\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - acc: 0.7465 - val_loss: 0.7300 - val_acc: 0.7240\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5365 - acc: 0.7257 - val_loss: 0.7400 - val_acc: 0.6615\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4969 - acc: 0.7569 - val_loss: 0.6421 - val_acc: 0.6823\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - acc: 0.7465 - val_loss: 0.6967 - val_acc: 0.6562\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - acc: 0.7500 - val_loss: 0.6815 - val_acc: 0.6927\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - acc: 0.7604 - val_loss: 0.6475 - val_acc: 0.6771\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - acc: 0.7622 - val_loss: 0.6319 - val_acc: 0.6927\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - acc: 0.7778 - val_loss: 0.6397 - val_acc: 0.6979\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - acc: 0.7726 - val_loss: 0.6658 - val_acc: 0.7188\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - acc: 0.7604 - val_loss: 0.6622 - val_acc: 0.6927\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - acc: 0.7812 - val_loss: 0.6384 - val_acc: 0.6719\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4901 - acc: 0.7622 - val_loss: 0.6512 - val_acc: 0.6823\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - acc: 0.7639 - val_loss: 0.6549 - val_acc: 0.6823\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4904 - acc: 0.7361 - val_loss: 0.7416 - val_acc: 0.6510\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5033 - acc: 0.7396 - val_loss: 0.6909 - val_acc: 0.6875\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5067 - acc: 0.7517 - val_loss: 0.6605 - val_acc: 0.7292\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4863 - acc: 0.7656 - val_loss: 0.6515 - val_acc: 0.7240\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - acc: 0.7795 - val_loss: 0.6600 - val_acc: 0.6823\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - acc: 0.7760 - val_loss: 0.6403 - val_acc: 0.6979\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5052 - acc: 0.7483 - val_loss: 0.6509 - val_acc: 0.7031\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - acc: 0.7587 - val_loss: 0.6668 - val_acc: 0.7031\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4802 - acc: 0.7743 - val_loss: 0.6671 - val_acc: 0.6823\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - acc: 0.7847 - val_loss: 0.7475 - val_acc: 0.6771\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - acc: 0.7535 - val_loss: 0.7334 - val_acc: 0.7188\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - acc: 0.7726 - val_loss: 0.6652 - val_acc: 0.6927\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - acc: 0.7726 - val_loss: 0.6966 - val_acc: 0.6875\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - acc: 0.7760 - val_loss: 0.6698 - val_acc: 0.7083\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - acc: 0.7812 - val_loss: 0.6438 - val_acc: 0.6927\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - acc: 0.7587 - val_loss: 0.6498 - val_acc: 0.6927\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - acc: 0.7587 - val_loss: 0.6518 - val_acc: 0.6667\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - acc: 0.7674 - val_loss: 0.6425 - val_acc: 0.7188\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - acc: 0.7882 - val_loss: 0.7298 - val_acc: 0.6719\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - acc: 0.7535 - val_loss: 0.6898 - val_acc: 0.7188\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - acc: 0.7760 - val_loss: 0.6499 - val_acc: 0.6875\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - acc: 0.7726 - val_loss: 0.6521 - val_acc: 0.6979\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - acc: 0.7639 - val_loss: 0.6486 - val_acc: 0.7031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucrl_X9eDflQ"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.title('Model Training Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19SYVY4DH7OW"
      },
      "source": [
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXejXzMaRMcB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}